# Voice Feedback Functionality

A comprehensive Spanish language learning application with AI-powered voice feedback and pronunciation scoring. Built with Next.js, Google AI (Gemini), and modern web technologies.

## ğŸ¯ Features

### ğŸ¤ Voice Recognition & Feedback
- **Real-time Speech Recognition** using Web Speech API
- **AI-Powered Pronunciation Analysis** with Google Gemini 2.0 Flash
- **Numerical Scoring System** (0-100) for accuracy, fluency, intonation, and overall performance
- **Detailed Text Feedback** with specific improvement suggestions
- **Confidence Scoring** (0-1) for AI assessment reliability

### ğŸ“š Learning Modules
- **Conversation Practice** with AI pronunciation feedback
- **Grammar Exercises** with interactive lessons
- **Reading Comprehension** with markdown content
- **Progress Tracking** with streak counting
- **Lesson Flagging** for difficult content review

### ğŸ¨ Modern UI/UX
- **Responsive Design** for mobile and desktop
- **Accessible Interface** with keyboard navigation
- **Optimized Bundle Size** with only necessary UI components
- **Smooth Animations** and transitions
- **Toast Notifications** for user feedback

### âš¡ Performance & Optimization
- **Direct Audio Analysis** for accurate pronunciation assessment
- **Minimal Bundle Size** with unused components removed
- **5-second Recording Limit** for optimal user experience
- **Smart Fallback System** for browser compatibility
- **Real-time Visual Feedback** during recording

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+ 
- Google AI API key ([Get one here](https://aistudio.google.com/))

### Installation

1. **Clone the repository**
   ```bash
   git clone git@github.com:Xavierhuang/voicefeedbackfunctionality.git
   cd voicefeedbackfunctionality
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Set up environment variables**
   ```bash
   echo "GOOGLE_API_KEY=your_google_ai_api_key_here" > .env.local
   ```

4. **Start the development server**
   ```bash
   npm run dev
   ```

5. **Open your browser**
   Navigate to [http://localhost:9002](http://localhost:9002)

## ğŸ“ Project Structure

```
src/
â”œâ”€â”€ ai/                          # AI integration
â”‚   â”œâ”€â”€ flows/                   # AI workflows
â”‚   â”‚   â”œâ”€â”€ audio-pronunciation-feedback.ts     # ğŸ¯ Core audio analysis
â”‚   â”‚   â”œâ”€â”€ generate-grammar-exercises.ts
â”‚   â”‚   â”œâ”€â”€ review-chat.ts
â”‚   â”‚   â””â”€â”€ text-to-speech.ts
â”‚   â”œâ”€â”€ dev.ts                   # Development AI server
â”‚   â””â”€â”€ genkit.ts               # Google AI configuration
â”œâ”€â”€ app/                        # Next.js app router
â”‚   â”œâ”€â”€ chat/                   # AI chat interface
â”‚   â”œâ”€â”€ learn/                  # Learning modules
â”‚   â”‚   â”œâ”€â”€ conversation/       # ğŸ¤ Voice practice
â”‚   â”‚   â”œâ”€â”€ grammar/           # Grammar lessons
â”‚   â”‚   â””â”€â”€ reading/           # Reading exercises
â”‚   â””â”€â”€ layout.tsx
â”œâ”€â”€ components/                 # React components
â”‚   â”œâ”€â”€ modules/               # Learning module components
â”‚   â”‚   â”œâ”€â”€ ConversationModule.tsx  # ğŸ¯ Main voice interface
â”‚   â”‚   â”œâ”€â”€ GrammarModule.tsx
â”‚   â”‚   â””â”€â”€ ArticleModule.tsx
â”‚   â””â”€â”€ ui/                    # Reusable UI components
â”œâ”€â”€ content/                   # Markdown lesson content
â”œâ”€â”€ context/                   # React context providers
â”œâ”€â”€ hooks/                     # Custom React hooks
â””â”€â”€ lib/                       # Utilities and types
```

## ğŸ¤ Voice Feedback System

### How It Works

1. **Audio Recording**: Uses MediaRecorder API to capture high-quality audio
2. **Direct Audio Analysis**: Google Gemini 2.0 Flash analyzes raw audio data
3. **Speech Recognition Fallback**: Web Speech API as backup for unsupported browsers
4. **AI Scoring**: Provides numerical scores (0-100) for multiple categories
5. **Detailed Feedback**: Delivers specific pronunciation improvement suggestions in English

### Scoring Categories

| Category | Description | Score Range |
|----------|-------------|-------------|
| **Accuracy** | Individual sounds and word pronunciation | 0-100 |
| **Fluency** | Rhythm, speed, and natural flow | 0-100 |
| **Intonation** | Pitch, tone, and stress patterns | 0-100 |
| **Overall** | Combined assessment score | 0-100 |
| **Confidence** | AI assessment reliability | 0-1 |

### Score Guidelines

- **90-100**: Excellent/Perfect pronunciation
- **80-89**: Very good with minor issues
- **70-79**: Good with some noticeable issues
- **60-69**: Fair with several issues
- **50-59**: Poor but understandable
- **0-49**: Very poor or unintelligible

## ğŸ”§ Configuration

### Environment Variables

```bash
# Required
GOOGLE_API_KEY=your_google_ai_api_key_here

# Optional (alternative)
GEMINI_API_KEY=your_gemini_api_key_here
```

### AI Model Configuration

The system uses Google Gemini 2.0 Flash for optimal performance:

```typescript
// src/ai/genkit.ts
export const ai = genkit({
  plugins: [googleAI()],
  model: 'googleai/gemini-2.0-flash',
});
```

## ğŸ“± Usage Examples

### Audio-Based Voice Practice

```typescript
import { getAudioPronunciationFeedback } from '@/ai/flows/audio-pronunciation-feedback';

const feedback = await getAudioPronunciationFeedback({
  audioData: "base64_encoded_audio_data",
  audioFormat: "webm", 
  targetPhrase: "Hola"
});

console.log(feedback);
// Output:
// {
//   isCorrect: true,
//   accuracyScore: 85,
//   fluencyScore: 78,
//   intonationScore: 92,
//   overallScore: 85,
//   confidence: 0.9,
//   transcribedText: "Hola",
//   accuracy: "Your pronunciation of 'Hola' was quite accurate...",
//   fluency: "The fluency was natural...",
//   intonation: "Your intonation was appropriate...",
//   overall: "Very good! Your pronunciation was excellent...",
//   specificIssues: []
// }
```

### Integration in React Component

```tsx
import { ConversationModule } from '@/components/modules/ConversationModule';

function MyApp() {
  return (
    <ConversationModule 
      lesson={lessonData}
      onComplete={() => console.log('Lesson completed!')}
    />
  );
}
```

## ğŸ› ï¸ Development

### Available Scripts

```bash
# Development
npm run dev              # Start development server (port 9002)
npm run genkit:dev       # Start AI development server
npm run genkit:watch     # Watch mode for AI server

# Production
npm run build           # Build for production
npm run start           # Start production server

# Code Quality
npm run lint            # Run ESLint
npm run typecheck       # Run TypeScript checks
```

### Adding New Voice Feedback Features

1. **Extend the AI schema** in `src/ai/flows/enhanced-pronunciation-feedback.ts`
2. **Update the UI** in `src/components/modules/ConversationModule.tsx`
3. **Add new lesson content** in `src/content/` or `src/lib/data.ts`

## ğŸ¨ Customization

### Styling

The app uses Tailwind CSS with a custom color scheme:

```css
/* Primary colors */
--primary: #30A2FF;      /* Deep sky blue */
--background: #F5F7FA;   /* Light gray */
--accent: #E91E63;       /* Vibrant magenta */
```

### Adding New Learning Modules

1. Create a new module component in `src/components/modules/`
2. Add the route in `src/app/learn/`
3. Update the lesson data in `src/lib/data.ts`

## ğŸ”’ Security

- API keys are stored in `.env.local` (not committed to git)
- Web Speech API requires HTTPS in production
- Input validation on all AI prompts

## ğŸŒ Browser Support

- **Chrome/Edge**: Full support (recommended)
- **Firefox**: Limited Web Speech API support
- **Safari**: Limited Web Speech API support
- **Mobile**: iOS Safari has limited support

## ğŸ“Š Performance

- **AI Response Time**: ~2-3 seconds average
- **Speech Recognition**: Real-time processing
- **Bundle Size**: Optimized with Next.js and Turbopack
- **Caching**: Automatic AI response caching

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

- **Issues**: [GitHub Issues](https://github.com/Xavierhuang/voicefeedbackfunctionality/issues)
- **Documentation**: [Genkit Docs](https://genkit.dev/docs/plugins/google-genai)
- **Google AI**: [AI Studio](https://aistudio.google.com/)

## ğŸ™ Acknowledgments

- [Google AI](https://ai.google/) for Gemini API
- [Genkit](https://genkit.dev/) for AI framework
- [Next.js](https://nextjs.org/) for React framework
- [Tailwind CSS](https://tailwindcss.com/) for styling
- [Radix UI](https://www.radix-ui.com/) for accessible components

---

**Built with â¤ï¸ for genuine language understanding**
